{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7f4823",
   "metadata": {},
   "source": [
    "# 详解Gradient Descent 梯度下降算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e56e4",
   "metadata": {},
   "source": [
    "## 引言"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fba4bb2",
   "metadata": {},
   "source": [
    " 梯度下降算法（Gradient Descent）依靠梯度逐渐下降的，进而下降到最优点（或局部最优点）来达到求解复杂函数极值点的原理。通过初始化参数，依靠梯度下降的逐步修改参数值，当梯度不在发生改变时（为0时），参数停止更新，达到极值点的目的。缺陷是迭代次数过多，也容易陷入局部最优解的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c4d33",
   "metadata": {},
   "source": [
    "## 数据引入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7179bf",
   "metadata": {},
   "source": [
    "> 默认数据为多样本多特征值的样本数据-----------$j$个样本3个特征值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3e84c",
   "metadata": {},
   "source": [
    "X：$(x_{1}^{(1)},x_{2}^{(1)},x_{3}^{(1)}),(x_{1}^{(2)},x_{2}^{(2)},x_{3}^{(2)}),(x_{1}^{(3)},x_{2}^{(3)},x_{3}^{(3)})...(x_{i-2}^{(j)},x_{i-1}^{(j)},x_{i}^{(j)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc26fee4",
   "metadata": {},
   "source": [
    "\n",
    "Y: $y^{(1)}  ,    y^{(2)}  ,y^{(3)} ...y^{(j)}$   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b0110",
   "metadata": {},
   "source": [
    "## 构造假设函数 Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e7531",
   "metadata": {},
   "source": [
    "$h_\\theta(x) = \\theta_{0}x_{0} + \\theta_{1}x_{1}+ \\theta_{2}x_{2}+...+ \\theta_{i}x_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e830d",
   "metadata": {},
   "source": [
    "## 代价函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a22d0f3",
   "metadata": {},
   "source": [
    "$J(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum_{j=1}^{m}(h_\\theta{(x^{(j)})} - y^{(j)})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e9030",
   "metadata": {},
   "source": [
    "## 梯度下降 Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc6e2e",
   "metadata": {},
   "source": [
    "$\\theta_j = \\theta_{j} - \\alpha \\frac{\\psi}{\\psi\\theta_{j}}J(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f7ccdb",
   "metadata": {},
   "source": [
    "* 适用于线性回归的Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d91e032",
   "metadata": {},
   "source": [
    "$\\theta_j = \\theta_{j} - \\alpha \\frac{1}{m}\\sum_{j=1}^{m} (h_\\theta{(x^{(j)})} - y^{(j)})x_{i}^{j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c9a20",
   "metadata": {},
   "source": [
    "令error = $h_\\theta{(x^{(j)})} - y^{(j)}$  每个样本的代价值如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e17e7e",
   "metadata": {},
   "source": [
    "$error = $ $$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    " h_\\theta{(x^{(1)})} - y^{(1)}\\\\\n",
    "h_\\theta{(x^{(2)})} - y^{(2)} \\\\\n",
    "h_\\theta{(x^{(3)})} - y^{(3)} \\\\\n",
    "...... \\\\\n",
    "h_\\theta{(x^{(j)})} - y^{(j)}\n",
    "\\end{matrix} \\right]\\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ae221",
   "metadata": {},
   "source": [
    "令$ X = x_{i}^{j}$   样本数据矩阵如下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38606dea",
   "metadata": {},
   "source": [
    "$X = $ $$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "x_{1}^{(1)}& x_{2}^{(1)}& x_{3}^{(1)}\\\\\n",
    "x_{1}^{(2)}& x_{2}^{(2)}& x_{3}^{(2)}\\\\\n",
    "x_{1}^{(3)}& x_{2}^{(3)}& x_{3}^{(3)}\\\\\n",
    "...... \\\\\n",
    "x_{1}^{(j)}& x_{2}^{(j)}& x_{3}^{(j)}\\\\\n",
    "\\end{matrix} \\right]\\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8335052",
   "metadata": {},
   "source": [
    "则$\\Theta$为如下  这里暂时不考虑$\\theta_{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff5c14",
   "metadata": {},
   "source": [
    "$\\Theta = $ $$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "\\theta_{1} \\\\\n",
    "\\theta_{2} \\\\\n",
    "\\theta_{3} \n",
    "\\end{matrix} \\right]\\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb24e6",
   "metadata": {},
   "source": [
    "其中 $\\Theta = \\Theta - \\alpha error$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aeea46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb6cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c47e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
